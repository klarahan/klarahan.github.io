---
title: "Chapter 3: Framing Left and Right"  
subtitle: "Online Appendix"
---

```{r setup, include=FALSE}
setwd("C:/Users/hanou/Dropbox/RESEARCH/klarahan.github.io")
Sys.setlocale(locale = "Korean")
```

Load libraries
```{r message=FALSE, warning=FALSE}
library(lubridate)
library(ggplot2)
library(dplyr)
library(tidytext)
library(quanteda)
library(scales)
library(LSX)

```

Load the data.
```{r}
data_ideo <- readRDS("data/data_ideo_nouns")
```

#Scaling
Load the Korean sentiment lexicon.
```{r emo, echo=FALSE}
# sentiment lexicon source:
# https://sites.google.com/site/datascienceslab/projects/multilingualsentiment
pos <- readr::read_delim("data/positive_words_ko.txt", delim='\t', col_names=c("term")) %>% 
  rename(word = term) %>% 
  tibble::add_column(sentiment = "positive")
neg <- readr::read_delim("data/negative_words_ko.txt", delim='\t', col_names=c("term")) %>% 
  rename(word = term) %>% 
  tibble::add_column(sentiment = "negative")
senti <- bind_rows(pos, neg) 
```

<!-- See the top sentiment words. -->
<!-- ```{r} -->
<!-- tidy_news <- data_ideo %>% -->
<!--   unnest_tokens(word, text) -->

<!-- tidy_news %>% -->
<!--   inner_join(senti) %>% -->
<!--   count(word, sort = TRUE) -->

<!-- senti_news <- tidy_news %>% -->
<!--   inner_join(senti) %>% -->
<!--   count(Newspaper, Prezparty, sentiment) %>% -->
<!--   tidyr::spread(sentiment, n, fill = 0) %>% -->
<!--   mutate(sentiment = positive - negative) -->

<!-- senti_word_counts <- tidy_news %>% -->
<!--   inner_join(senti) %>% -->
<!--   filter(Government == "1990-1993 Roh TW") %>% -->
<!--   count(word, sentiment, Government, sort = TRUE) %>% -->
<!--   ungroup() -->

<!-- senti_word_counts -->
<!-- ``` -->

<!-- Plot the top sentiment words. -->
<!-- ```{r message=TRUE, warning=TRUE} -->
<!-- senti_word_counts %>% -->
<!--   group_by(sentiment) %>% -->
<!--   top_n(30) %>% -->
<!--   ungroup() %>% -->
<!--   mutate(word = reorder(word, n)) %>% -->
<!--   ggplot(aes(word, n, fill = sentiment)) + -->
<!--   geom_col(show.legend = FALSE) + -->
<!--   facet_wrap(~sentiment, scales = "free_y") + -->
<!--   labs(y = "Contribution to sentiment", -->
<!--        x = NULL) + -->
<!--   coord_flip() + -->
<!--   scale_fill_grey() + -->
<!--   theme_bw() -->
<!-- ``` -->

See the top sentiment words.
```{r}
tidy_news <- data_ideo %>%
  unnest_tokens(word, text)

tidy_news %>%
  inner_join(senti) %>%
  count(word, sort = TRUE)

news_words


news_words <- tidy_news %>%
  count(Newspaper, word, sort = TRUE)

total_words <- news_words %>% 
  group_by(Newspaper) %>% 
  summarize(total = sum(n))

news_words <- left_join(news_words, total_words)

```

```{r}
news_tf_idf <- news_words %>%
  bind_tf_idf(word, Newspaper, n)

news_tf_idf %>%
  select(-total) %>%
  arrange(desc(tf_idf))

library(forcats)

news_tf_idf %>%
  group_by(Newspaper) %>%
  slice_max(tf_idf, n = 15) %>%
  ungroup() %>%
  ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = Newspaper)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~Newspaper, ncol = 2, scales = "free") +
  labs(x = "tf-idf", y = NULL)

```


<!-- ```{r} -->
<!-- Sys.setlocale(locale = "C") -->
<!-- dict_sentiment <- dictionary(list(right = c("제시", "모색", "지속", "가치", "대의", "수용"), -->
<!--                                  left = c("비판", "비난", "싸움", "공격", "갈등", "대립"))) -->
<!-- dict_sentiment -->
<!-- ``` -->


```{r}
Sys.setlocale(locale = "C")
dict_sentiment <- dictionary(list(right = c("수구", "권위", "안보", "독재", "퇴행"),
                                 left = c("좌경", "종북", "민중", "딱지", "내란")))
dict_sentiment
```

```{r}

# tokenize text corpus and remove various features
corp_sent <- data_ideo %>% 
  unique() %>% 
  mutate(Body = gsub("</?[^>]+>|▲ 종이신문보기", "", Body)) %>% 
  corpus() %>% 
  corpus_reshape(to =  "sentences")
toks <- corp_sent %>% 
    tokens()

# create a document feature matrix from the tokens object
dfmat <- toks %>% 
    dfm(remove = "") %>% 
    dfm_trim(min_termfreq = 5)
```

```{r}
topfeatures(dfmat, 20)

```

```{r}
seed <- as.seedwords(dict_sentiment)
seed
```

```{r}
# identify context words 
context_terms <- char_context(toks, pattern = c("*진보*", "*보수*", "*좌파*", "*우파*"), p = 0.05)

# run LSS model
tmod_lss <- textmodel_lss(dfmat, seeds = seed,
                          terms = context_terms, k = 300, cache = TRUE)
```

```{r}
head(coef(tmod_lss), 20) # most positive words

```

```{r}
tail(coef(tmod_lss), 20) # most negative words

```

```{r}
textplot_terms(tmod_lss, dict_sentiment[c("negative", "positive")])
ggsave("plots/3_ideo_seeds.jpg", width=7, height=4, dpi = 300)

```

```{r}
dfmat <- dfm_group(dfmat)
# predict sentiment scores
pred <- as.data.frame(predict(tmod_lss, se.fit = TRUE, newdata = dfmat))
pred$date <- docvars(dfmat, "Date")
pred$Newspaper <- docvars(dfmat, "Newspaper")

```

```{r}
pred_sm_chos <- pred %>% 
  filter(Newspaper == "Chosun") %>% 
  smooth_lss(engine = "locfit")
pred_sm_hani <- pred %>% 
  filter(Newspaper == "Hankyoreh") %>% 
  smooth_lss(engine = "locfit")
pred_sm_hankook <- pred %>% 
  filter(Newspaper == "Hankook") %>% 
  smooth_lss(engine = "locfit")

Sys.setlocale(locale = "Korean")
head(pred_sm_chos)
head(pred_sm_hani)
head(pred_sm_hankook)

```

plot trend ggplot2
```{r}
x <- bind_rows("Chosun" = pred_sm_chos, "Hankyoreh" = pred_sm_hani, .id = "Newspaper") %>% 
  mutate(date = as.Date(date, format = "ymd")) %>% 
  mutate(Newspaper = as.factor(Newspaper)) %>% 
  ggplot(aes(date, fit, group = Newspaper, color = Newspaper, fill = Newspaper)) +
  annotate("rect", xmin = as.Date("1998-02-25"), xmax = as.Date("2008-02-2"), 
           ymin = -Inf, ymax = Inf, alpha = 0.2) +
  geom_line() +
  geom_ribbon(aes(ymin = fit + se.fit, ymax = fit - se.fit), alpha = 0.3) +
  geom_hline(yintercept = 0) +
  scale_color_manual(values = c("grey20", "grey70")) +
  theme_bw() +
  labs(x = "Year", y = "Negative vs. Positive",
       caption = "1. First Inter-Korean Summit\n2. Start of three-day mass protests against the US FTA\n3. 2012 presidential election and victory of Park Geun-hye")  +
  scale_x_date(breaks = "1 year", labels = date_format("%Y"), 
           limits = as.Date(c("1990-01-01", "2014-12-31")), expand = c(0,0)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        legend.position = "top")  +
  scale_fill_manual(values=c("grey20", "grey70")) +
  annotate(geom = "text", x = as.Date("1994-01-01"), y = 0.65, 
           label = "Conservative\ngovernments", hjust = "center") +
  annotate(geom = "text", x = as.Date("2003-01-01"), y = 0.65, 
           label = "Liberal\ngovernments", hjust = "center") +
  annotate(geom = "text", x = as.Date("2012-01-01"), y = 0.65, 
         label = "Conservative\ngovernments", hjust = "center") +
  annotate(geom = "text", x = as.Date("2000-06-13"), y = 0.4, 
         label = "1", hjust = "center", size = 4) +
  annotate(geom = "text", x = as.Date("2008-06-05"), y = 0.4, 
         label = "2", hjust = "center", size = 4) +
  annotate(geom = "text", x = as.Date("2012-06-12"), y = 0.4, 
         label = "3", hjust = "center", size = 4) +
  annotate("segment", x = as.Date(c("2000-06-13", "2008-06-05", "2012-06-12")),
           xend = as.Date(c("2000-06-13", "2008-06-05", "2012-06-12")), 
           y = - Inf, yend = 0.42, linetype = 3)

x
ggsave("plots/3_ideo_lss.jpg", width=9, height= 6, dpi = 300)

```
Look up key periods
```{r}
data_ideo %>% 
  filter(Date > "2001-06-01" & Date < "2001-12-01") %>%
  unique() %>% 
  mutate(Body = gsub("</?[^>]+>|▲ 종이신문보기", "", Body)) %>% 
  select(Body)
```

# Keyness
Load the data.
```{r}
data_ideo <- readRDS("data/toks_ideo")
```

Prepare and check
```{r}
Sys.setlocale(locale = "C")

stopwords <- c("그래픽", "지난해", "한겨레", "기사", "기자", "본지", "측은", "작년", "신문", "종이", "우리", "지면", "보도", "생각", "이날", "간의", "조선일보", "입장")
# stopwords_wild <- c("경제민주화*")

data_words <- data_ideo %>% 
  tokens_subset(!docvars(data_ideo, "Newspaper") == "Hankook" &  
                docvars(data_ideo, "Government") == "2008-2013 Lee MB" &  
                docvars(data_ideo, "Keyword") == "right") %>% 
  tokens_remove(pattern = stopwords, valuetype = "fixed") %>%
  # tokens_remove(pattern = stopwords_wild, valuetype = "glob") %>% 
  dfm()

Sys.setlocale(locale = "Korean")
tstat_freq <- data_words %>% 
  dfm() %>% 
  textstat_frequency(n = 20)
head(tstat_freq, 40)

#text scaling
result_keyness <- textstat_keyness(data_words, target = docvars(data_words, "Newspaper") == "Chosun") 
textplot_keyness(result_keyness, n = 10, color = c("grey20", "grey80")) 

data_words2 <- data_ideo %>% 
  tokens_subset(!docvars(data_ideo, "Newspaper") == "Hankook" &  
                docvars(data_ideo, "Government") == "2013-2014 Park GH" &  
                docvars(data_ideo, "Keyword") == "left") %>% 
  tokens_remove(pattern = stopwords, valuetype = "fixed") %>%
  # tokens_remove(pattern = stopwords_wild, valuetype = "glob") %>% 
  dfm()

Sys.setlocale(locale = "Korean")
tstat_freq <- data_words2 %>% 
  dfm() %>% 
  textstat_frequency(n = 20)
head(tstat_freq, 40)

#text scaling
result_keyness2 <- textstat_keyness(data_words2, target = docvars(data_words2, "Newspaper") == "Chosun") 
textplot_keyness(result_keyness2, n = 10, color = c("grey20", "grey80")) 



```
Look up stray words
```{r}
Sys.setlocale(locale = "C")
x <- data_ideo %>% 
  tokens_subset(docvars(data_ideo, "Newspaper") == "Hankyoreh") %>% 
  kwic(pattern = "문화방송", window = 5, valuetype = "fixed")
Sys.setlocale(locale = "Korean")
x
```

Plot and label
```{r message=FALSE, warning=FALSE}
x <- textplot_keyness(result_keyness, n = 10) +
  xlim(-1100, 2000) +
  labs(color = "Newspaper", subtitle = "2008-2013 Lee MB government (conservative)",
       caption = "x-axis: chi-squared test for significance of observed versus expected frequency") +
  scale_color_manual(values = c("black", "grey80"), 
                     labels = c("Chosun Ilbo", "Hankyoreh")) +
  annotate("text", x = -30, y = 20, label = "North Korea", hjust = 1) +
  annotate("text", x = -30, y = 19, label = "leftists", hjust = 1) +
  annotate("text", x = -30, y = 18, label = "party", hjust = 1) +
  annotate("text", x = -30, y = 17, label = "superintendent (of education)", hjust = 1) +
  annotate("text", x = -30, y = 16, label = "MP", hjust = 1) +
  annotate("text", x = -30, y = 15, label = "candidate", hjust = 1) +
  annotate("text", x = -30, y = 14, label = "Republic of Korea", hjust = 1) +
  annotate("text", x = -30, y = 13, label = "advance", hjust = 1) +
  annotate("text", x = -30, y = 12, label = "rightists", hjust = 1) +
  annotate("text", x = -30, y = 11, label = "Hannara Party", hjust = 1) +
  annotate("text", x = 30, y = 10, label = "Munhwa Broadcasting Corporation (MBC)", hjust = 0) +
  annotate("text", x = 30, y = 9, label = "temporary worker", hjust = 0)  +
  annotate("text", x = 30, y = 8, label = "broadcast", hjust = 0) +
  annotate("text", x = 30, y = 7, label = "comprehensive programming channels", hjust = 0) +
  annotate("text", x = 30, y = 6, label = "labor", hjust = 0) +
  annotate("text", x = 30, y = 5, label = "worker", hjust = 0) +
  annotate("text", x = 30, y = 4, label = "society", hjust = 0) +
  annotate("text", x = 30, y = 3, label = "media", hjust = 0)+
  annotate("text", x = 30, y = 2, label = "laughter", hjust = 0) +
  annotate("text", x = 30, y = 1, label = "welfare", hjust = 0)

x
ggsave("plots/3_ideo_keyness.jpg", width=7, height=4, dpi = 300)

```



